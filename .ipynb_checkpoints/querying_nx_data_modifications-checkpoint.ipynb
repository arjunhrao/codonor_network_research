{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting program\n",
      "212\n",
      "22366\n",
      "1.0\n",
      "['ROBERT ANDREWS', 'BERNARD SANDERS', 'GEORGE ALLEN', 'SPENCER BACHUS', 'EDWARD ROYCE', 'PETER HOEKSTRA', 'ROBERT MENENDEZ', 'MIKE COFFMAN', 'TOM LATHAM', 'LLOYD DOGGETT', 'JESSE JACKSON', 'DIANA DEGETTE', 'JAMES MCGOVERN', 'JOHN TIERNEY', 'DEBBIE STABENOW', 'JO EMERSON', 'WILLIAM PASCRELL', 'CAROLYN MCCARTHY', 'MIKE MCINTYRE', 'RONALD KIND', 'LOIS CAPPS', 'BARBARA LEE', 'HEATHER WILSON', 'JUDY BIGGERT', 'SHELLEY BERKLEY', 'RUSH HOLT', 'PAUL RYAN', 'TAMMY BALDWIN', 'MARIA CANTWELL', 'DIANNE FEINSTEIN', 'DANIEL LUNGREN', 'BILL NELSON', 'DAVID GILL', 'STENY HOYER', 'THOMAS CARPER', 'MARCY KAPTUR', 'BENJAMIN CARDIN', 'PETER DEFAZIO', 'LOUISE SLAUGHTER', 'FREDERICK UPTON', 'NANCY PELOSI', 'NITA LOWEY', 'ILEANA ROS-LEHTINEN', 'JEFFRY FLAKE', 'MICHAEL HONDA', 'TODD AKIN', 'DENNIS REHBERG', 'STEVE ISRAEL', 'PATRICK TIBERI', 'ERIC CANTOR', 'SHELLEY CAPITO', 'RAUL GRIJALVA', 'STEVEN KING', 'BEN CHANDLER', 'SCOTT GARRETT', 'TIMOTHY BISHOP', 'TIM MURPHY', 'THOMAS HENSARLING', 'CONNIE MACK', 'DEBBIE WASSERMAN SCHULTZ', 'THOMAS PRICE', 'JOHN BARROW', 'JR BOUSTANY', 'JERRY MCNERNEY', 'JOSEPH DONNELLY', 'BETTY SUTTON', 'DONNA EDWARDS', 'ALAN GRAYSON', 'DANIEL MAFFEI', 'PETER ROSKAM', 'AMY KLOBUCHAR', 'CLAIRE MCCASKILL', 'JON TESTER', 'ROBERT CASEY', 'SHELDON WHITEHOUSE', 'L. DUCKWORTH', 'KEVIN MCCARTHY', 'CHRISTOPHER MURPHY', 'VERNON BUCHANAN', 'MAZIE HIRONO', 'BRUCE BRALEY', 'DAVID LOEBSACK', 'TIMOTHY WALZ', 'KEITH ELLISON', 'DEAN HELLER', 'CAROL SHEA-PORTER', 'G. FOSTER', 'NICOLA TSONGAS', 'ANN KIRKPATRICK', 'JARED POLIS', 'JIM HIMES', 'GARY PETERS', 'ERIK PAULSEN', 'MARTIN HEINRICH', 'PAUL TONKO', 'KURT SCHRADER', 'GERRY CONNOLLY', 'ANDREW HARRIS', 'JOE GARCIA', 'JUDY CHU', 'WILLIAM OWENS', 'JOHN GARAMENDI', 'MARK CRITZ', 'JEFF DENHAM', 'WILLIAM SOUTHERLAND', 'RAYMOND CRAVAACK', 'NAN HAYWORTH', 'ANN BUERKLE', 'JAMES RENACCI', 'PATRICK MEEHAN', 'DAVID CICILLINE', 'KRISTI NOEM', 'ROBERT HURT', 'SEAN DUFFY', 'REID RIBBLE', 'SCOTT BROWN', 'AMERISH BERA', 'KAREN HARRINGTON', 'GARY MCDOWELL', 'ANN KUSTER', 'RANDOLPH ALTSCHULER', 'MANAN TRIVEDI', 'DENNIS HECK', 'SUZAN DELBENE', 'PEDRO PIERLUISI', 'RICHARD CARMONA', 'LINDA LINGLE', 'ELIZABETH WARREN', 'ANGUS KING', 'HEIDI HEITKAMP', 'DEBRA FISCHER', 'JOSEPH KYRILLOS', 'TOM SMITH', 'RAFAEL CRUZ', 'TIMOTHY KAINE', 'TOMMY THOMPSON', 'SCOTT TIPTON', 'ALLEN WEST', 'ROBERT DOLD', 'TIMOTHY SCOTT', 'FRANCISCO CANSECO', 'KATHLEEN HOCHUL', 'JANICE HAHN', 'WILLIAM ENYART', 'TOBIAS SCHLINGENSIEPEN', 'JOE MANCHIN', 'RICHARD NOLAN', 'RICHARD MOURDOCK', 'GARLAND BARR', 'THOMAS COTTON', 'RONALD BARBER', 'KYRSTEN SINEMA', 'ALAN LOWENTHAL', 'JULIA BROWNLEY', 'JOSE HERNANDEZ', 'RICKY GILL', 'RAUL RUIZ', 'MARK TAKANO', 'SCOTT PETERS', 'SALVATORE PACE', 'BRANDON SHAFFER', 'JOE MIKLOSI', 'ELIZABETH ESTY', 'ANDREW RORABACK', 'VALDEZ DEMINGS', 'KEITH FITZGERALD', 'LOIS FRANKEL', 'PATRICK MURPHY', 'ADAM HASNER', 'CHRISTIE VILSACK', 'NICOLE LEFAVOUR', 'BRADLEY SCHNEIDER', 'CHERI BUSTOS', 'BRENDAN MULLEN', 'SHELLI YODER', 'RICHARD TISEI', 'JOSEPH KENNEDY', 'JOHN DELANEY', 'DANIEL KILDEE', 'JAMES GRAVES', 'ANN WAGNER', 'PAM GULLESON', 'SHELLEY ADLER', 'JOHN OCEGUERA', 'STEVEN HORSFORD', 'JULIAN SCHREIBMAN', 'GRACE MENG', 'HAKEEM JEFFRIES', 'MARK MURPHY', 'NATHAN SHINAGAWA', 'SEAN MALONEY', 'JOYCE BEATTY', 'ANGELA ZIMMANN', 'ROB WALLACE', 'SUZANNE BONAMICI', 'TOM RICE', 'MATT VARILEK', 'PETE GALLEGO', 'ROGER WILLIAMS', 'MIA LOVE', 'PAUL HIRSCHBIEL', 'ERNEST POWELL', 'JOHN DOUGLASS', 'DEREK KILMER', 'ROB ZERBAN', 'MARK POCAN', 'PATRICK KREITLOW', 'SUSAN THORN', 'PATRICIA KEEVER', 'ROBERT KERREY', 'MICHELE BACHMANN', 'KIRSTEN GILLIBRAND']\n"
     ]
    }
   ],
   "source": [
    "#read graph as edge list\n",
    "print('starting program')\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "#codonor graph - nodes are recipients. Edges are number of donors in common.\n",
    "H1 = nx.read_edgelist('co_donor_test.txt',nodetype=str,delimiter='\\t!\\t')#data=(('number_of_codonors',int)))\n",
    "\n",
    "print(nx.number_of_nodes(H1) )#should be 212\n",
    "print( nx.number_of_edges(H1) )#should be 22366\n",
    "print(nx.density(H1) )\n",
    "\n",
    "#We want to relabel the nodes, replacing \"LastName, FirstName MiddleName MiddleName2\" with \"FirstName LastName\"\n",
    "def mapping(full_name):\n",
    "    name = [x for x in full_name.split(',')]\n",
    "    #name must be of length two.\n",
    "    #The first 'name' is the lastname\n",
    "    lastName = name[0]\n",
    "    #rest of name is second part of 'name'. The firstName is that part split by spaces to get the first word\n",
    "    #note there is a preceding space\n",
    "    firstName = name[1].split(' ')[1]\n",
    "    #godammit there's someone named W Todd Akin\n",
    "    if (len(firstName) == 1 and len(name[1].split(' ')) > 2):#if we have 2+ names in the firstName middleName etc\n",
    "        firstName = name[1].split(' ')[2]\n",
    "    return firstName + \" \" + lastName\n",
    "\n",
    "H1=nx.relabel_nodes(H1,mapping)\n",
    "print(H1.nodes())#Nodes change confirmed\n",
    "#print(H1.edges())#Edges change too.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of the number of codonors\n",
    "num_codonors_list = []\n",
    "for e in H1.edges(data=True):\n",
    "    #e is a tuple\n",
    "    temp = (e[2])['number_of_codonors']\n",
    "    num_codonors_list.append(temp)\n",
    "#print(num_codonors_list)\n",
    "\n",
    "#get a list of the edges and sort by num codonors\n",
    "list_of_edges = []\n",
    "for e in H1.edges(data=True):\n",
    "    list_of_edges.append(e)\n",
    "list_of_edges = sorted(H1.edges(data=True), key=lambda tup: tup[2]['number_of_codonors'])#sort by number of codonors\n",
    "#print(list_of_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#want to plot distribution of num_codonors, each element of which is a value in the affinity matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "h = sorted(num_codonors_list)\n",
    "#Bunch of 0's for initial ones. The last sorted values are:\n",
    "#..., 12946, 13815, 14003, 14022, 14520, 15825, 17183, 18845, 21054, 21388, 22655, 29957, 40203]\n",
    "\n",
    "#https://stackoverflow.com/questions/34291260/how-can-i-plot-multiple-figure-in-the-same-line-with-matplotlib\n",
    "#https://stackoverflow.com/questions/16392921/make-more-than-one-chart-in-same-ipython-notebook-cell\n",
    "#https://matplotlib.org/gallery/subplots_axes_and_figures/multiple_figs_demo.html\n",
    "\n",
    "data = sorted(num_codonors_list)\n",
    "counts, bins, bars = plt.hist(data, bins=20)\n",
    "print(counts)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#plt.figure(1)\n",
    "#plt.subplot(211)\n",
    "bins = 2**(np.arange(0,10))\n",
    "#plt.xscale('log')\n",
    "counts, bins, bars = plt.hist(data,bins=bins)\n",
    "print(counts)\n",
    "plt.show()\n",
    "\n",
    "#plt.subplot(212)\n",
    "bins = 2**(np.arange(0,10))\n",
    "plt.xscale('log')\n",
    "counts, bins, bars = plt.hist(data,bins=bins)\n",
    "print(counts)\n",
    "plt.show()\n",
    "\n",
    "print(list_of_edges[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_edges:\n",
      "22366\n",
      "1118.3\n",
      "high_bkt len:\n",
      "1118\n",
      "mid_bkt len:\n",
      "5591\n",
      "low_bkt len:\n",
      "15657\n"
     ]
    }
   ],
   "source": [
    "num_edges = len(list_of_edges)\n",
    "print(\"num_edges:\")\n",
    "print(num_edges)\n",
    "print(float(.05*num_edges))\n",
    "high_bkt = []#all edges above the 5% mark\n",
    "high_cutoff = num_edges - float(.05*num_edges)\n",
    "mid_bkt = []\n",
    "mid_cutoff = num_edges - float(.3*num_edges)\n",
    "low_bkt = []\n",
    "\n",
    "for e in range(num_edges):\n",
    "    if e >= high_cutoff:\n",
    "        high_bkt.append(list_of_edges[e])\n",
    "    elif e >= mid_cutoff:\n",
    "        mid_bkt.append(list_of_edges[e])\n",
    "    else:\n",
    "        low_bkt.append(list_of_edges[e])\n",
    "        \n",
    "#print(high_bkt)\n",
    "print(\"high_bkt len:\")\n",
    "print(len(high_bkt))\n",
    "print(\"mid_bkt len:\")\n",
    "print(len(mid_bkt))\n",
    "print(\"low_bkt len:\")\n",
    "print(len(low_bkt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm just going to do the entire high bucket as opposed to sampling from the lower ones because in the past the lower ones have led to poor results - at least in Google CSE, the values were often 0, which is undesirable. Doing the entire bucket as opposed to randomly sampling also allows me to not to overlap the edges I query on Google. I can always randomly sample from the bucket afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#host google.com 8.8.8.8\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#had to write a scraping method to work for me until I figure out why I can't find the server...\n",
    "def jaccard_google_search_scrape(search_term1, search_term2, api_key, cse_id, **kwargs):\n",
    "\n",
    "    r = requests.get(\"https://www.google.com/search\", params={'q':search_term1})\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    res = soup.find(\"div\", {\"id\": \"resultStats\"})\n",
    "    num1 = -2\n",
    "    if (res.text.replace(\",\", \"\").split()[0].strip() == \"About\"):\n",
    "        num1 = int(res.text.replace(\",\", \"\").split()[1].strip() )\n",
    "    else:\n",
    "        num1 = int(res.text.replace(\",\", \"\").split()[0].strip() )\n",
    "\n",
    "    r = requests.get(\"https://www.google.com/search\", params={'q':search_term2})\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    res = soup.find(\"div\", {\"id\": \"resultStats\"})\n",
    "    num2 = -2\n",
    "    if (res.text.replace(\",\", \"\").split()[0].strip() == \"About\"):\n",
    "        num2 = int(res.text.replace(\",\", \"\").split()[1].strip() )\n",
    "    else:\n",
    "        num2 = int(res.text.replace(\",\", \"\").split()[0].strip() )\n",
    "    \n",
    "    strBoth = search_term1 + ' ' + search_term2#I think this should be fine. There's so much noise anyways,\n",
    "    #and sometimes it increases the number of results, sometimes decreases, so using AND isn't better.\n",
    "    \n",
    "    r = requests.get(\"https://www.google.com/search\", params={'q':strBoth})\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    res = soup.find(\"div\", {\"id\": \"resultStats\"})\n",
    "    numCommon = -2\n",
    "    if (res.text.replace(\",\", \"\").split()[0].strip() == \"About\"):\n",
    "        numCommon = int(res.text.replace(\",\", \"\").split()[1].strip() )\n",
    "    else:\n",
    "        numCommon = int(res.text.replace(\",\", \"\").split()[0].strip() )\n",
    "    \n",
    "    num1 = int(num1)\n",
    "    num2 = int(num2)\n",
    "    numCommon = int(numCommon)\n",
    "    #print('num results for str1:' + str(num1) )\n",
    "    #print('num results for str2:' + str(num2) )\n",
    "    #print('num results in common:' + str(numCommon) )\n",
    "    \n",
    "    \n",
    "    #sometimes denominator was 0. try except ZeroDivionError.\n",
    "    try:\n",
    "        jacInd = numCommon /(num1+num2-numCommon) #can still use / for regular division, but want decimals here.\n",
    "    except ZeroDivisionError:\n",
    "        jacInd = -1\n",
    "    \n",
    "    try:\n",
    "        divMin = numCommon / min(num1, num2)\n",
    "    except ZeroDivisionError:\n",
    "        divMin = -1\n",
    "    try:\n",
    "        divProd = numCommon / (num1*num2)\n",
    "    except:\n",
    "        divProd = -1\n",
    "    #retList is of format: num results for str1, num results for str2, num results in common, the Jaccard index,\n",
    "    #the intersection / the min, and the intersection / the product\n",
    "    retList = [num1, num2, numCommon, jacInd, divMin, divProd]\n",
    "    return retList\n",
    "\n",
    "print(\"method processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ALAN GRAYSON', 'JULIA BROWNLEY', {'number_of_codonors': 722})\n"
     ]
    }
   ],
   "source": [
    "#Figure out which edges to sample\n",
    "instanceNum = 2#same thing as like a machineNum\n",
    "start = 61\n",
    "end = 61+40\n",
    "#start = instanceNum*33\n",
    "#end = start + 33#we can technically do 33 edges safely\n",
    "#Note that if instanceNum were 1, we'd have [33:66].\n",
    "all_edges_to_sample = high_bkt[start:end]#partition based on machine number\n",
    "print(all_edges_to_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a40af1b5cc4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmy_api_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_cse_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_google_search_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_api_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_cse_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#   retList = [num1, num2, numCommon, jacInd, divMin, divProd]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     dfRow = pd.DataFrame([[edge[0], edge[1], (edge[2])['number_of_codonors'], res[0], res[1], res[2], res[3], res[4], res[5]]], \n",
      "\u001b[0;32m<ipython-input-5-3342f921e409>\u001b[0m in \u001b[0;36mjaccard_google_search_scrape\u001b[0;34m(search_term1, search_term2, api_key, cse_id, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"resultStats\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnum2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"About\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnum2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#space out requests more - want to write a cron script eventually for maybe ~6-8 requests per hour as opposed\n",
    "#to 100 per day which means 33 edges per day\n",
    "#import time\n",
    "#time.sleep(1)\n",
    "\n",
    "\n",
    "#choose the first of the following two lines if it's the very start / origination of the file. Otherwise go with second\n",
    "#don't forget to save csv at the end\n",
    "dfRes = pd.DataFrame(columns = [\"str1\", \"str2\", \"num_codonors\", \"num1\", \"num2\", \"numCommon\", \"jacInd\", \"divMin\", \"divProd\"])\n",
    "#dfRes = pd.read_csv('./co_donor_google_queries_fin_6.csv')\n",
    "\n",
    "counter = start\n",
    "savestr = './data/codonor_network_queries_instance_' + str(instanceNum) + '_5.20_highbkt_edges_' + str(start) + '_to_' + str(end-1) + '.csv'\n",
    "#'''\n",
    "try:\n",
    "    for edge in all_edges_to_sample:\n",
    "        #time.sleep(1)\n",
    "        print(counter)\n",
    "        counter = counter + 1\n",
    "        name1 = '\"' + edge[0] + '\"'\n",
    "        name2 = '\"' + edge[1] + '\"'\n",
    "\n",
    "        my_api_key, my_cse_id = \"0\", \"0\"\n",
    "        res = jaccard_google_search_scrape(name1, name2, my_api_key, my_cse_id, num=1)\n",
    "        #   retList = [num1, num2, numCommon, jacInd, divMin, divProd]\n",
    "        dfRow = pd.DataFrame([[edge[0], edge[1], (edge[2])['number_of_codonors'], res[0], res[1], res[2], res[3], res[4], res[5]]], \n",
    "                           columns = [\"str1\", \"str2\", \"num_codonors\", \"num1\", \"num2\", \"numCommon\", \"jacInd\", \"divMin\", \"divProd\"])\n",
    "\n",
    "        dfRes = dfRes.append(dfRow, ignore_index=True)\n",
    "except:\n",
    "    dfRes.to_csv(savestr)\n",
    "    print('saved in except')\n",
    "print('queries done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "dfRes.to_csv(savestr)\n",
    "print('saved no error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
